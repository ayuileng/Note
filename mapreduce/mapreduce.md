* 并行计算技术的分类：
    1. Flynn分类法：依据计算机在单个时间点能够处理的指令流数量和依据计算机在单个时间点能处理的数据流数量
    2. 按存储访问结构分类：共享内存访问结构、分布式内存访问结构和分布共享式内存访问结构
    3. 按系统类型分类：多核并行计算系统、对称多处理系统（多个相同类型的处理器通过总线连接并共享存储器）、大规模并行处理系统（专用内联网连接组成）、集群（网络连接的普通商用计算机）和网格（用网络连接的一组异构计算机构成的）。
    4. 按应用的计算特征分类：数据密集型（数据量大但是计算简单）、计算密集型（数据不大但是计算复杂的并行处理）和两者混合
    5. 按并行程序设计方式：共享存储变量方式、消息传递方式、mapreduce方式和其他（mapreduce难以满足高实时性和高数据相关性的大数据处理需求）
* 并行计算面临的主要问题：
    1. 网络互联技术
    2. 存储访问体系结构
    3. 分布式数据和文件管理
    4. 并行计算的任务划分和算法设计
    5. 并行程序设计模型和语言
    6. 数据访问和通信控制
    7. 可靠性和容错性
* 大数据的5大特点：
    1. 大体量
    2. 多样性
    3. 时效性
    4. 准确性
    5. 大价值
* 大数据的分类：
    1. 结构化、半结构化和非结构化
    2. 批处理和流式计算
    3. 传统的查询分析和复杂的数据挖掘
    4. 实时和非实时
    5. 简单关系数据和复杂关系数据
* 大数据主要技术层面
    1. 基础设施层：大数据分布存储和并行计算的硬件基础和平台，比如集群等
    2. 系统软件层：分布式文件系统和数据查询管理系统，大数据并行计算模式和系统
    3. 并行化算法层和应用层
* mapreduce：基于集群的高性能并行计算平台、并行计算与运行软件框架、并行程序设计模型与方法。
* mapreduce的处理过程：
    1. 对大量顺序式数据元素或记录进行扫描；
    2. 对每个数据元素进行处理，获取中间结果信息；
    3. 排序和整理中间结果以便后续处理；
    4. 收集整理中间结果；
    5. 结果输出
    6. 1和2是map的工作，4和5是reduce的工作
* mapreduce主要功能：
    1. 自动数据划分和计算任务调度
    2. 数据和代码互定位（一个基本原则是本地化数据处理，即尽可能处理本地磁盘上面的数据），实现了代码向数据的迁移
    3. 系统优化：减少数据通信开销，在进入reduce之前会有合并处理
    4. 出错检测和恢复
* mapreduce主要技术特征：
    1. 向外扩展而不是向上扩展：选用大量便宜的而不是选一些很贵的服务器
    2. 失效被认为是常态
    3. 代码向数据迁移
    4. 顺序处理数据，避免随机访问
    5. 为开发者封装细节
    6. 平滑的可扩展性
* HDFS:hadoop给予每个从节点上的本地文件系统，构建一个逻辑上整体化的分布式文件系统，以此提供大规模可扩展的分布式数据存储功能。其中主控节点叫做NameNode，从节点叫做DataNode
* HBase：HDFS难以管理结构化/半结构化的海量数据，所以hadoop提供了一个大规模分布式数据库管理和查询系统HBase。HBase是一个建立在HDFS上的一个NoSQL，提供了对结构化/半结构化甚至非结构化的大数据的实时读写和随机访问能力。
* Hive：建立在hadoop上的数据仓库，主要用来管理存储于HDFS或HBase中的数据，可以使用类似SQL的HiveQL来进行查询，并且HiveQL能在底层实现时转换为相应的mapreduce程序
* HDFS的6种特征：
    1. 大规模数据分布存储能力
    2. 高并发访问能力
    3. 强大的容错能力
    4. 顺序式文件访问：大数据批处理主要方式是顺序处理，所以HDFS支持大数据的快速顺序读出，但是随机访问效率差
    5. 一致性模型：支持大量数据一次写入，多次读取，不支持写入数据的更新操作，但是允许在文件末尾添加
    6. 数据块存储模式：采用大粒度数据块存储文件，默认64MB
* NameNode是一个主服务器，用来管理整个文件系统的命名空间和元数据，以及处理外界的文件访问请求；NameNode主要保存了文件系统的3中元数据：
    1. 命名空间，即整个分布式文件系统的目录结构
    2. 数据块对应文件名的映射表
    3. 每个数据块副本的位置信息
* HDFS文件访问过程：
    1. 用户的应用程序通过客户端将文件名发送到NameNode
    2. NameNode接收到后在HDFS目录中检索对应的数据块，再根据数据块的信息找到保存数据块的DataNode地址，返回给客户端
    3. 客户端收到响应后与DataNode并行的进行数据传输，并将操作结果日志等提交到NameNode
* 